{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tasked in developing an algorithm in order to detect certain lowercase cursive letters. The program should be able to detect which letter is in an imported image and output the accuracy of that letter being the predicted letter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define base and data paths\n",
    "base_path = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5\"\n",
    "data_dir = os.path.join(base_path, \"Data\")\n",
    "\n",
    "# Define ZIP file paths\n",
    "cursive_zip = os.path.join(data_dir, \"Cursive.zip\")\n",
    "kaggle_zip = os.path.join(data_dir, \"archive.zip\")\n",
    "\n",
    "# Define extraction directories\n",
    "cursive_extract_path = os.path.join(data_dir, \"Cursive\")\n",
    "kaggle_extract_path = os.path.join(data_dir, \"Signatures\")\n",
    "\n",
    "# Make sure folders exist\n",
    "os.makedirs(cursive_extract_path, exist_ok=True)\n",
    "os.makedirs(kaggle_extract_path, exist_ok=True)\n",
    "\n",
    "# --- Unzip the Cursive dataset ---\n",
    "try:\n",
    "    with zipfile.ZipFile(cursive_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(cursive_extract_path)\n",
    "    print(f\"Successfully extracted Cursive.zip to: {cursive_extract_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find Cursive.zip in the Data folder.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: Cursive.zip appears to be corrupted or invalid.\")\n",
    "\n",
    "# --- Unzip the Kaggle signature dataset ---\n",
    "'''\n",
    "try:\n",
    "    with zipfile.ZipFile(kaggle_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(kaggle_extract_path)\n",
    "    print(f\"Successfully extracted archive.zip to: {kaggle_extract_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find archive.zip in the Data folder.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: archive.zip appears to be corrupted or invalid.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jpg_files = glob.glob(f\"{extract_path}/**/*.jpg\", recursive=True)\n",
    "heic_files = glob.glob(f\"{extract_path}/**/*.heic\", recursive=True)\n",
    "png_files = glob.glob(f\"{extract_path}/**/*.png\", recursive=True)\n",
    "\n",
    "print(\"JPG count:\", len(jpg_files))\n",
    "print(\"HEIC count:\", len(heic_files))\n",
    "print(\"PNG count:\", len(png_files))\n",
    "\n",
    "\n",
    "sample = random.choice(jpg_files)\n",
    "img = cv2.imread(sample)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(f\"Sample image: {sample.split('/')[-1]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define dataset paths\n",
    "base_dir = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5/Data\"\n",
    "cursive_dir = os.path.join(base_dir, \"Cursive\")\n",
    "signatures_dir = os.path.join(base_dir, \"Signatures\", \"sign_data\")\n",
    "\n",
    "# Define a helper to count images recursively\n",
    "def count_images(folder, exts=(\".jpg\", \".jpeg\", \".png\")):\n",
    "    total = 0\n",
    "    for root, _, files in os.walk(folder):\n",
    "        total += sum(f.lower().endswith(exts) for f in files)\n",
    "    return total\n",
    "\n",
    "# Count images in both datasets\n",
    "cursive_count = count_images(cursive_dir)\n",
    "signature_count = count_images(signatures_dir)\n",
    "\n",
    "print(\"Dataset Summary\")\n",
    "print(f\"Cursive dataset path: {cursive_dir}\")\n",
    "print(f\"Number of Cursive images: {cursive_count:,}\")\n",
    "\n",
    "print(f\"\\nSignature dataset path: {signatures_dir}\")\n",
    "print(f\"Number of Signature images: {signature_count:,}\")\n",
    "\n",
    "# Check if folders exist and are non-empty\n",
    "if not os.path.exists(cursive_dir):\n",
    "    print(\"\\nWarning: Cursive directory not found!\")\n",
    "elif cursive_count == 0:\n",
    "    print(\"\\nCursive directory found but contains no images.\")\n",
    "\n",
    "if not os.path.exists(signatures_dir):\n",
    "    print(\"\\nWarning: Signatures directory not found!\")\n",
    "elif signature_count == 0:\n",
    "    print(\"\\nSignature directory found but contains no images.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "base_path = \"Data/Signatures/sign_data/sign_data/train\"\n",
    "subject_folders = [f\"S{i}\" for i in range(1, 36)]\n",
    "\n",
    "viable_images = []\n",
    "corrupted_images = []\n",
    "converted_count = 0\n",
    "\n",
    "for folder in subject_folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        continue\n",
    "    \n",
    "    for img_file in glob.glob(f\"{folder_path}/*.*\"):\n",
    "        # Convert to JPG if not already\n",
    "        if not img_file.lower().endswith(\".jpg\"):\n",
    "            try:\n",
    "                with Image.open(img_file) as im:\n",
    "                    im = im.convert(\"RGB\")  # ensure it's RGB\n",
    "                    new_path = os.path.splitext(img_file)[0] + \".jpg\"\n",
    "                    im.save(new_path, \"JPEG\")\n",
    "                    converted_count += 1\n",
    "                    os.remove(img_file)  # remove original\n",
    "                    img_file = new_path  # update path to new jpg\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {img_file}: {e}\")\n",
    "                corrupted_images.append(img_file)\n",
    "                continue\n",
    "        \n",
    "        # Check if OpenCV can read it\n",
    "        try:\n",
    "            img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                corrupted_images.append(img_file)\n",
    "            else:\n",
    "                viable_images.append(img_file)\n",
    "        except Exception as e:\n",
    "            corrupted_images.append(img_file)\n",
    "\n",
    "print(f\"Total files converted to JPG: {converted_count}\")\n",
    "print(f\"Total viable images: {len(viable_images)}\")\n",
    "print(f\"Total corrupted/unreadable images: {len(corrupted_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# -------------------------\n",
    "# Elastic transform\n",
    "# -------------------------\n",
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "    shape = image.shape\n",
    "    dx = random_state.uniform(-1, 1, size=shape) \n",
    "    dy = random_state.uniform(-1, 1, size=shape)\n",
    "    dx = cv2.GaussianBlur(dx, ksize=(0,0), sigmaX=sigma) * alpha\n",
    "    dy = cv2.GaussianBlur(dy, ksize=(0,0), sigmaX=sigma) * alpha\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
    "    map_x = (x + dx).astype(np.float32)\n",
    "    map_y = (y + dy).astype(np.float32)\n",
    "    transformed = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return transformed\n",
    "\n",
    "# -------------------------\n",
    "# Dataset class with augmentation\n",
    "# -------------------------\n",
    "class LetterDataset(Dataset):\n",
    "    def __init__(self, data_list, label2idx=None, img_size=128, augment=False, elastic_prob=0.2):\n",
    "        \"\"\"\n",
    "        data_list: [(path, label), ...] or [path, ...] (for unlabeled)\n",
    "        label2idx: dict mapping label->int (None if unlabeled)\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.label2idx = label2idx\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.elastic_prob = elastic_prob\n",
    "        self.has_labels = isinstance(data_list[0], tuple) and len(data_list[0]) == 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_labels:\n",
    "            img_path, label = self.data_list[idx]\n",
    "            label_idx = self.label2idx[label]\n",
    "        else:\n",
    "            img_path = self.data_list[idx]\n",
    "            label_idx = 0  # dummy\n",
    "\n",
    "        img = self._load_image(img_path)\n",
    "        if self.augment:\n",
    "            img = self._augment(img)\n",
    "\n",
    "        img_tensor = torch.FloatTensor(img).unsqueeze(0)\n",
    "        return img_tensor, label_idx\n",
    "\n",
    "    def _load_image(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            img = np.zeros((self.img_size, self.img_size), dtype=np.float32)\n",
    "        if img.shape != (self.img_size, self.img_size):\n",
    "            img = cv2.resize(img, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        return img.astype(np.float32) / 255.0\n",
    "\n",
    "    def _augment(self, img):\n",
    "        # 1) Rotation ±15°\n",
    "        if np.random.rand() > 0.3:\n",
    "            angle = np.random.uniform(-15, 15)\n",
    "            center = (self.img_size // 2, self.img_size // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            img = cv2.warpAffine(img, M, (self.img_size, self.img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "        # 2) Scaling 0.85 - 1.15\n",
    "        if np.random.rand() > 0.3:\n",
    "            scale = np.random.uniform(0.85, 1.15)\n",
    "            new_size = max(2, int(self.img_size * scale))\n",
    "            resized = cv2.resize(img, (new_size, new_size), interpolation=cv2.INTER_AREA)\n",
    "            output = np.zeros((self.img_size, self.img_size), dtype=np.float32)\n",
    "            if scale >= 1.0:\n",
    "                start = (new_size - self.img_size) // 2\n",
    "                output = resized[start:start+self.img_size, start:start+self.img_size]\n",
    "            else:\n",
    "                start = (self.img_size - new_size) // 2\n",
    "                output[start:start+new_size, start:start+new_size] = resized\n",
    "            img = output\n",
    "\n",
    "        # 3) Translation ±8 px\n",
    "        if np.random.rand() > 0.35:\n",
    "            tx = int(np.random.randint(-8, 9))\n",
    "            ty = int(np.random.randint(-8, 9))\n",
    "            M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            img = cv2.warpAffine(img, M, (self.img_size, self.img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "        # 4) Elastic deformation\n",
    "        if np.random.rand() < min(self.elastic_prob + 0.05, 0.3):\n",
    "            alpha = np.random.uniform(6, 14)\n",
    "            sigma = np.random.uniform(3, 5)\n",
    "            img = elastic_transform(img, alpha, sigma)\n",
    "\n",
    "        # 5) Brightness/contrast jitter\n",
    "        if np.random.rand() > 0.35:\n",
    "            alpha = np.random.uniform(0.85, 1.15)\n",
    "            beta = np.random.uniform(-0.07, 0.07)\n",
    "            img = np.clip(alpha * img + beta, 0, 1)\n",
    "\n",
    "        # 6) Gaussian noise\n",
    "        if np.random.rand() > 0.55:\n",
    "            noise = np.random.normal(0, 0.02, img.shape)\n",
    "            img = np.clip(img + noise, 0, 1)\n",
    "\n",
    "        # 7) Optional slight blur\n",
    "        if np.random.rand() > 0.8:\n",
    "            img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "        return img.astype(np.float32)\n",
    "\n",
    "# -------------------------\n",
    "# VISUALIZE AUGMENTED SAMPLES\n",
    "# -------------------------\n",
    "import random\n",
    "\n",
    "# Take 5 random samples from the training dataset with augmentation\n",
    "augmented_samples = random.sample(train_data, 10)\n",
    "augmented_dataset = LetterDataset(augmented_samples, label2idx, IMG_SIZE, augment=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(augmented_samples), figsize=(15, 3))\n",
    "for i, (img_tensor, label_idx) in enumerate(augmented_dataset):\n",
    "    img = img_tensor.squeeze(0).numpy()\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {idx2label[label_idx]}\")\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle(\"Augmented Samples\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Ensemble Cursive Letter Classifier with Test-Time Augmentation\n",
    "Trains multiple models and ensembles predictions for max accuracy\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Configuration\n",
    "CURSIVE_DIR = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5/Data/Processed/Cursive\"\n",
    "SIGN_DIR = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5/Data/Processed/Signatures\"\n",
    "IMG_SIZE = 96\n",
    "BATCH_SIZE = 16\n",
    "INITIAL_EPOCHS = 80\n",
    "FINE_TUNE_EPOCHS = 25\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CONFIDENCE_THRESHOLD = 0.80\n",
    "NUM_MODELS = 3  # Train 3 models for ensemble\n",
    "TTA_ROUNDS = 5  # Test-time augmentation rounds\n",
    "\n",
    "print(f\"Device: {DEVICE}, Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Training {NUM_MODELS} models for ensemble\")\n",
    "\n",
    "\n",
    "def load_cursive_data(cursive_dir):\n",
    "    labeled_data = []\n",
    "    valid_exts = {'.png', '.jpg', '.jpeg'}\n",
    "    if not os.path.exists(cursive_dir):\n",
    "        return labeled_data\n",
    "\n",
    "    for s_folder in sorted(os.listdir(cursive_dir)):\n",
    "        s_path = os.path.join(cursive_dir, s_folder)\n",
    "        if not os.path.isdir(s_path):\n",
    "            continue\n",
    "\n",
    "        for f in os.listdir(s_path):\n",
    "            if any(f.lower().endswith(ext) for ext in valid_exts):\n",
    "                label = f[0].lower()\n",
    "                if 'a' <= label <= 'z':\n",
    "                    labeled_data.append((os.path.join(s_path, f), label))\n",
    "    return labeled_data\n",
    "\n",
    "\n",
    "def load_signatures(sign_dir):\n",
    "    valid_exts = {'.png', '.jpg', '.jpeg'}\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(sign_dir):\n",
    "        for f in files:\n",
    "            if any(f.lower().endswith(ext) for ext in valid_exts):\n",
    "                paths.append(os.path.join(root, f))\n",
    "    return paths\n",
    "\n",
    "\n",
    "def apply_augmentation(img, strength='medium'):\n",
    "    \"\"\"Apply augmentation to image with different strengths\"\"\"\n",
    "    img_size = img.shape[0]\n",
    "    \n",
    "    if strength == 'light':\n",
    "        # Light augmentation for TTA\n",
    "        if np.random.rand() > 0.5:\n",
    "            angle = np.random.uniform(-5, 5)\n",
    "            M = cv2.getRotationMatrix2D((img_size//2, img_size//2), angle, 1.0)\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        if np.random.rand() > 0.5:\n",
    "            tx = np.random.randint(-3, 4)\n",
    "            ty = np.random.randint(-3, 4)\n",
    "            M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    elif strength == 'medium':\n",
    "        # Medium augmentation for training\n",
    "        if np.random.rand() > 0.4:\n",
    "            angle = np.random.uniform(-15, 15)\n",
    "            M = cv2.getRotationMatrix2D((img_size//2, img_size//2), angle, 1.0)\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        if np.random.rand() > 0.5:\n",
    "            tx = np.random.randint(-10, 11)\n",
    "            ty = np.random.randint(-10, 11)\n",
    "            M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        if np.random.rand() > 0.5:\n",
    "            scale = np.random.uniform(0.85, 1.15)\n",
    "            new_size = int(img_size * scale)\n",
    "            img_scaled = cv2.resize(img, (new_size, new_size))\n",
    "            if scale > 1:\n",
    "                start = (new_size - img_size) // 2\n",
    "                img = img_scaled[start:start+img_size, start:start+img_size]\n",
    "            else:\n",
    "                img_new = np.ones((img_size, img_size), dtype=np.float32)\n",
    "                start = (img_size - new_size) // 2\n",
    "                img_new[start:start+new_size, start:start+new_size] = img_scaled\n",
    "                img = img_new\n",
    "        \n",
    "        if np.random.rand() > 0.5:\n",
    "            alpha = np.random.uniform(0.85, 1.15)\n",
    "            beta = np.random.uniform(-0.1, 0.1)\n",
    "            img = np.clip(alpha * img + beta, 0, 1)\n",
    "        \n",
    "        if np.random.rand() > 0.7:\n",
    "            noise = np.random.normal(0, 0.02, img.shape)\n",
    "            img = np.clip(img + noise, 0, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "class LetterDataset(Dataset):\n",
    "    def __init__(self, data_list, label2idx, img_size=96, augment=False):\n",
    "        self.data_list = data_list\n",
    "        self.label2idx = label2idx\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.has_labels = isinstance(data_list[0], tuple)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_labels:\n",
    "            img_path, label = self.data_list[idx]\n",
    "            label_idx = self.label2idx[label]\n",
    "        else:\n",
    "            img_path = self.data_list[idx]\n",
    "            label_idx = 0\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            img = np.zeros((self.img_size, self.img_size), dtype=np.float32)\n",
    "        if img.shape != (self.img_size, self.img_size):\n",
    "            img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        \n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        if self.augment:\n",
    "            img = apply_augmentation(img, strength='medium')\n",
    "\n",
    "        img_tensor = torch.FloatTensor(img).unsqueeze(0)\n",
    "        return img_tensor, label_idx\n",
    "\n",
    "\n",
    "class SimplerCNN(nn.Module):\n",
    "    def __init__(self, num_classes, img_size=96):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 256)\n",
    "        self.bn_fc = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device, use_mixup=True):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    \n",
    "    for imgs, labels in tqdm(loader, leave=False, desc=\"Training\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        # Apply Mixup augmentation\n",
    "        if use_mixup and np.random.rand() > 0.5:\n",
    "            lam = np.random.beta(0.2, 0.2)\n",
    "            idx = torch.randperm(imgs.size(0))\n",
    "            mixed_imgs = lam * imgs + (1 - lam) * imgs[idx]\n",
    "            labels_a, labels_b = labels, labels[idx]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mixed_imgs)\n",
    "            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            total_correct += (lam * (outputs.argmax(1) == labels_a).float() + \n",
    "                            (1 - lam) * (outputs.argmax(1) == labels_b).float()).sum().item()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "        total_samples += imgs.size(0)\n",
    "    \n",
    "    return total_loss / total_samples, total_correct / total_samples * 100\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_samples += imgs.size(0)\n",
    "    \n",
    "    return total_loss / total_samples, total_correct / total_samples * 100\n",
    "\n",
    "\n",
    "def predict_with_tta(models, img_tensor, device, n_augments=TTA_ROUNDS):\n",
    "    \"\"\"Test-time augmentation with ensemble\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Original prediction\n",
    "            pred = F.softmax(model(img_tensor.to(device)), dim=1)\n",
    "            all_predictions.append(pred)\n",
    "            \n",
    "            # Augmented predictions\n",
    "            for _ in range(n_augments):\n",
    "                # Create augmented version\n",
    "                img_np = img_tensor.squeeze().cpu().numpy()\n",
    "                aug_img = apply_augmentation(img_np, strength='light')\n",
    "                aug_tensor = torch.FloatTensor(aug_img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "                \n",
    "                pred = F.softmax(model(aug_tensor), dim=1)\n",
    "                all_predictions.append(pred)\n",
    "    \n",
    "    # Average all predictions\n",
    "    avg_pred = torch.stack(all_predictions).mean(dim=0)\n",
    "    return avg_pred\n",
    "\n",
    "\n",
    "def train_single_model(train_loader, val_loader, test_loader, num_classes, model_idx, random_seed):\n",
    "    \"\"\"Train a single model with given seed\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Model {model_idx + 1}/{NUM_MODELS} (seed={random_seed})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    model = SimplerCNN(num_classes, IMG_SIZE).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    patience = 0\n",
    "    max_patience = 20\n",
    "\n",
    "    for epoch in range(1, INITIAL_EPOCHS + 1):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE, use_mixup=True)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(f\"Epoch {epoch}/{INITIAL_EPOCHS}\")\n",
    "            print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "            print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'best_model_{model_idx}_phase1.pth')\n",
    "            patience = 0\n",
    "            if epoch % 10 == 0 or epoch == 1:\n",
    "                print(f\"  ✓ New best model saved! Val Acc: {val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= max_patience:\n",
    "                print(f\"  Early stopping triggered after {epoch} epochs\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(f'best_model_{model_idx}_phase1.pth'))\n",
    "    print(f\"Best Phase 1 Val Accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return model, best_val_acc\n",
    "\n",
    "\n",
    "def main():\n",
    "    labeled_data = load_cursive_data(CURSIVE_DIR)\n",
    "    signature_paths = load_signatures(SIGN_DIR)\n",
    "    print(f\"Loaded {len(labeled_data)} cursive images\")\n",
    "    print(f\"Loaded {len(signature_paths)} signature images\")\n",
    "\n",
    "    if len(labeled_data) == 0:\n",
    "        raise RuntimeError(\"No labeled cursive images found!\")\n",
    "\n",
    "    labels = sorted(set(lbl for _, lbl in labeled_data))\n",
    "    label2idx = {lbl: i for i, lbl in enumerate(labels)}\n",
    "    idx2label = {i: lbl for lbl, i in label2idx.items()}\n",
    "    num_classes = len(labels)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    train_data, temp_data = train_test_split(labeled_data, test_size=0.2, \n",
    "                                             stratify=[lbl for _, lbl in labeled_data], \n",
    "                                             random_state=42)\n",
    "    val_data, test_data = train_test_split(temp_data, test_size=0.5, \n",
    "                                           stratify=[lbl for _, lbl in temp_data], \n",
    "                                           random_state=42)\n",
    "\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "    train_dataset = LetterDataset(train_data, label2idx, IMG_SIZE, augment=True)\n",
    "    val_dataset = LetterDataset(val_data, label2idx, IMG_SIZE, augment=False)\n",
    "    test_dataset = LetterDataset(test_data, label2idx, IMG_SIZE, augment=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Train ensemble of models\n",
    "    models = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for i in range(NUM_MODELS):\n",
    "        model, val_acc = train_single_model(train_loader, val_loader, test_loader, \n",
    "                                           num_classes, i, random_seed=42 + i * 100)\n",
    "        models.append(model)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Ensemble Training Complete!\")\n",
    "    print(f\"Individual model val accuracies: {[f'{acc:.2f}%' for acc in val_accs]}\")\n",
    "    print(f\"Average val accuracy: {np.mean(val_accs):.2f}%\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Pseudo-label with ensemble\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PHASE 2: Pseudo-labeling with ensemble\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    pseudo_data = []\n",
    "    sig_dataset = LetterDataset([(p, 'a') for p in signature_paths], label2idx, IMG_SIZE, augment=False)\n",
    "    sig_loader = DataLoader(sig_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (imgs, _) in enumerate(tqdm(sig_loader, desc=\"Pseudo-labeling\")):\n",
    "            # Get ensemble prediction\n",
    "            predictions = []\n",
    "            for model in models:\n",
    "                pred = F.softmax(model(imgs.to(DEVICE)), dim=1)\n",
    "                predictions.append(pred)\n",
    "            \n",
    "            avg_pred = torch.stack(predictions).mean(dim=0)\n",
    "            conf, pred_idx = avg_pred.max(1)\n",
    "            \n",
    "            if conf.item() >= CONFIDENCE_THRESHOLD:\n",
    "                pseudo_data.append((signature_paths[idx], idx2label[pred_idx.item()]))\n",
    "\n",
    "    print(f\"Pseudo-labeled {len(pseudo_data)}/{len(signature_paths)} signatures ({len(pseudo_data)/len(signature_paths)*100:.1f}%)\")\n",
    "\n",
    "    # Fine-tune each model\n",
    "    if len(pseudo_data) > 50:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PHASE 3: Fine-tuning ensemble with pseudo-labels\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        combined_train = train_data + pseudo_data\n",
    "        combined_dataset = LetterDataset(combined_train, label2idx, IMG_SIZE, augment=True)\n",
    "        combined_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            print(f\"\\nFine-tuning Model {i+1}/{NUM_MODELS}\")\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=LR * 0.1, weight_decay=0.01)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=7)\n",
    "            \n",
    "            best_val_acc = 0\n",
    "            patience = 0\n",
    "            max_patience = 15\n",
    "            \n",
    "            for epoch in range(1, FINE_TUNE_EPOCHS + 1):\n",
    "                train_loss, train_acc = train_epoch(model, combined_loader, criterion, optimizer, DEVICE)\n",
    "                val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "                scheduler.step(val_acc)\n",
    "                \n",
    "                if epoch % 5 == 0:\n",
    "                    print(f\"  Epoch {epoch}/{FINE_TUNE_EPOCHS} - Val Acc: {val_acc:.2f}%\")\n",
    "                \n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    torch.save(model.state_dict(), f'best_model_{i}_final.pth')\n",
    "                    patience = 0\n",
    "                else:\n",
    "                    patience += 1\n",
    "                    if patience >= max_patience:\n",
    "                        break\n",
    "            \n",
    "            model.load_state_dict(torch.load(f'best_model_{i}_final.pth'))\n",
    "            print(f\"  Best fine-tuned val acc: {best_val_acc:.2f}%\")\n",
    "\n",
    "    # Final evaluation with TTA and ensemble\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL EVALUATION WITH ENSEMBLE + TTA\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Testing with TTA\"):\n",
    "        for i in range(imgs.size(0)):\n",
    "            img = imgs[i:i+1]\n",
    "            label = labels[i]\n",
    "            \n",
    "            # Get ensemble + TTA prediction\n",
    "            pred_probs = predict_with_tta(models, img, DEVICE, n_augments=TTA_ROUNDS)\n",
    "            pred = pred_probs.argmax(1).item()\n",
    "            \n",
    "            all_preds.append(pred)\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "    test_acc = (np.array(all_preds) == np.array(all_labels)).mean() * 100\n",
    "    print(f\"\\n{'*'*60}\")\n",
    "    print(f\"FINAL TEST ACCURACY (Ensemble + TTA): {test_acc:.2f}%\")\n",
    "    print(f\"{'*'*60}\\n\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, \n",
    "                              target_names=[idx2label[i] for i in range(num_classes)], \n",
    "                              zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[idx2label[i] for i in range(num_classes)],\n",
    "                yticklabels=[idx2label[i] for i in range(num_classes)],\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.title(f'Confusion Matrix - Test Accuracy: {test_acc:.2f}%', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_ensemble.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, letter in enumerate([idx2label[j] for j in range(num_classes)]):\n",
    "        print(f\"  {letter}: {per_class_acc[i]*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n✓ Training complete! Best models saved\")\n",
    "    print(f\"✓ Confusion matrix saved as 'confusion_matrix_ensemble.png'\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Ensemble Cursive Letter Classifier with Test-Time Augmentation\n",
    "Trains multiple models and ensembles predictions for max accuracy\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# ------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------\n",
    "CURSIVE_DIR = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5/Data/Processed/Cursive\"\n",
    "SIGN_DIR = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5/Data/Processed/Signatures\"\n",
    "IMG_SIZE = 96\n",
    "BATCH_SIZE = 16\n",
    "INITIAL_EPOCHS = 80\n",
    "FINE_TUNE_EPOCHS = 25\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CONFIDENCE_THRESHOLD = 0.80\n",
    "NUM_MODELS = 3\n",
    "TTA_ROUNDS = 5\n",
    "\n",
    "print(f\"Device: {DEVICE}, Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Training {NUM_MODELS} models for ensemble\")\n",
    "\n",
    "# ------------------------\n",
    "# DATA LOADING FUNCTIONS\n",
    "# ------------------------\n",
    "def load_cursive_data(cursive_dir):\n",
    "    labeled_data = []\n",
    "    valid_exts = {'.png', '.jpg', '.jpeg'}\n",
    "    if not os.path.exists(cursive_dir):\n",
    "        return labeled_data\n",
    "\n",
    "    for s_folder in sorted(os.listdir(cursive_dir)):\n",
    "        s_path = os.path.join(cursive_dir, s_folder)\n",
    "        if not os.path.isdir(s_path):\n",
    "            continue\n",
    "\n",
    "        for f in os.listdir(s_path):\n",
    "            if any(f.lower().endswith(ext) for ext in valid_exts):\n",
    "                label = f[0].lower()\n",
    "                if 'a' <= label <= 'z':\n",
    "                    labeled_data.append((os.path.join(s_path, f), label))\n",
    "    return labeled_data\n",
    "\n",
    "def load_signatures(sign_dir):\n",
    "    valid_exts = {'.png', '.jpg', '.jpeg'}\n",
    "    paths = []\n",
    "    for root, dirs, files in os.walk(sign_dir):\n",
    "        for f in files:\n",
    "            if any(f.lower().endswith(ext) for ext in valid_exts):\n",
    "                paths.append(os.path.join(root, f))\n",
    "    return paths\n",
    "\n",
    "# ------------------------\n",
    "# AUGMENTATION\n",
    "# ------------------------\n",
    "def apply_augmentation(img, strength='medium'):\n",
    "    img_size = img.shape[0]\n",
    "    if strength == 'light':\n",
    "        if np.random.rand() > 0.5:\n",
    "            angle = np.random.uniform(-5, 5)\n",
    "            M = cv2.getRotationMatrix2D((img_size//2, img_size//2), angle, 1.0)\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "        if np.random.rand() > 0.5:\n",
    "            tx = np.random.randint(-3, 4)\n",
    "            ty = np.random.randint(-3, 4)\n",
    "            M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "    elif strength == 'medium':\n",
    "        if np.random.rand() > 0.4:\n",
    "            angle = np.random.uniform(-15, 15)\n",
    "            M = cv2.getRotationMatrix2D((img_size//2, img_size//2), angle, 1.0)\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "        if np.random.rand() > 0.5:\n",
    "            tx = np.random.randint(-10, 11)\n",
    "            ty = np.random.randint(-10, 11)\n",
    "            M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "        if np.random.rand() > 0.5:\n",
    "            scale = np.random.uniform(0.85, 1.15)\n",
    "            new_size = int(img_size * scale)\n",
    "            img_scaled = cv2.resize(img, (new_size, new_size))\n",
    "            if scale > 1:\n",
    "                start = (new_size - img_size) // 2\n",
    "                img = img_scaled[start:start+img_size, start:start+img_size]\n",
    "            else:\n",
    "                img_new = np.ones((img_size, img_size), dtype=np.float32)\n",
    "                start = (img_size - new_size) // 2\n",
    "                img_new[start:start+new_size, start:start+new_size] = img_scaled\n",
    "                img = img_new\n",
    "        if np.random.rand() > 0.5:\n",
    "            alpha = np.random.uniform(0.85, 1.15)\n",
    "            beta = np.random.uniform(-0.1, 0.1)\n",
    "            img = np.clip(alpha * img + beta, 0, 1)\n",
    "        if np.random.rand() > 0.7:\n",
    "            noise = np.random.normal(0, 0.02, img.shape)\n",
    "            img = np.clip(img + noise, 0, 1)\n",
    "    return img\n",
    "\n",
    "# ------------------------\n",
    "# DATASET CLASS\n",
    "# ------------------------\n",
    "class LetterDataset(Dataset):\n",
    "    def __init__(self, data_list, label2idx, img_size=96, augment=False):\n",
    "        self.data_list = data_list\n",
    "        self.label2idx = label2idx\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.has_labels = isinstance(data_list[0], tuple)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_labels:\n",
    "            img_path, label = self.data_list[idx]\n",
    "            label_idx = self.label2idx[label]\n",
    "        else:\n",
    "            img_path = self.data_list[idx]\n",
    "            label_idx = 0\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            img = np.zeros((self.img_size, self.img_size), dtype=np.float32)\n",
    "        if img.shape != (self.img_size, self.img_size):\n",
    "            img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        if self.augment:\n",
    "            img = apply_augmentation(img, strength='medium')\n",
    "\n",
    "        img_tensor = torch.FloatTensor(img).unsqueeze(0)\n",
    "        return img_tensor, label_idx\n",
    "\n",
    "# ------------------------\n",
    "# MODEL DEFINITION\n",
    "# ------------------------\n",
    "class SimplerCNN(nn.Module):\n",
    "    def __init__(self, num_classes, img_size=96):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        self.fc1 = nn.Linear(256*2*2, 256)\n",
    "        self.bn_fc = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x); x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x); x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x); x = self.dropout(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x); x = self.dropout(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------\n",
    "# TRAINING / VALIDATION FUNCTIONS\n",
    "# ------------------------\n",
    "def train_epoch(model, loader, criterion, optimizer, device, use_mixup=True):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    for imgs, labels in tqdm(loader, leave=False, desc=\"Training\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        if use_mixup and np.random.rand() > 0.5:\n",
    "            lam = np.random.beta(0.2, 0.2)\n",
    "            idx = torch.randperm(imgs.size(0))\n",
    "            mixed_imgs = lam * imgs + (1 - lam) * imgs[idx]\n",
    "            labels_a, labels_b = labels, labels[idx]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mixed_imgs)\n",
    "            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            total_correct += (lam * (outputs.argmax(1) == labels_a).float() +\n",
    "                              (1-lam) * (outputs.argmax(1) == labels_b).float()).sum().item()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total_samples += imgs.size(0)\n",
    "    return total_loss/total_samples, total_correct/total_samples*100\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_samples += imgs.size(0)\n",
    "    return total_loss/total_samples, total_correct/total_samples*100\n",
    "\n",
    "# ------------------------\n",
    "# MAIN PIPELINE\n",
    "# ------------------------\n",
    "def main():\n",
    "    labeled_data = load_cursive_data(CURSIVE_DIR)\n",
    "    signature_paths = load_signatures(SIGN_DIR)\n",
    "    if len(labeled_data) == 0:\n",
    "        raise RuntimeError(\"No labeled cursive images found!\")\n",
    "\n",
    "    labels = sorted(set(lbl for _, lbl in labeled_data))\n",
    "    label2idx = {lbl: i for i, lbl in enumerate(labels)}\n",
    "    idx2label = {i: lbl for lbl, i in label2idx.items()}\n",
    "    num_classes = len(labels)\n",
    "\n",
    "    train_data, temp_data = train_test_split(labeled_data, test_size=0.2,\n",
    "                                             stratify=[lbl for _, lbl in labeled_data],\n",
    "                                             random_state=42)\n",
    "    val_data, test_data = train_test_split(temp_data, test_size=0.5,\n",
    "                                           stratify=[lbl for _, lbl in temp_data],\n",
    "                                           random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(LetterDataset(train_data, label2idx, IMG_SIZE, augment=True),\n",
    "                              batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(LetterDataset(val_data, label2idx, IMG_SIZE, augment=False),\n",
    "                            batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(LetterDataset(test_data, label2idx, IMG_SIZE, augment=False),\n",
    "                             batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    models = []\n",
    "    for i in range(NUM_MODELS):\n",
    "        model = SimplerCNN(num_classes, IMG_SIZE).to(DEVICE)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "        best_val_acc = 0\n",
    "        for epoch in range(1, INITIAL_EPOCHS+1):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                # Save with joblib\n",
    "                joblib.dump(model.state_dict(), f'best_model_{i}_phase1.joblib')\n",
    "        # Load best model\n",
    "        model.load_state_dict(joblib.load(f'best_model_{i}_phase1.joblib'))\n",
    "        models.append(model)\n",
    "\n",
    "    print(\"✓ Ensemble training complete. Models saved with joblib.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses a neural network to recognize handwritten cursive letters. Images from “Cursive” and “Signatures” folders were preprocessed by resizing, grayscaling, and normalizing pixel values. Data augmentation—including rotations, translations, scaling, brightness adjustments, and noise was applied during training to improve generalization. The CNN architecture consists of four layers with batch normalization, adaptive pooling, and fully connected layers. Models were trained on labeled cursive data, then pseudo-labeling was applied to signature images for fine-tuning. Test-time augmentation and ensemble averaging were used during inference to improve accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# ------------------------\n",
    "# CONFIG\n",
    "# ------------------------\n",
    "MODEL_PATH = \"best_model_0_phase1.joblib\"  # adjust which model to load\n",
    "IMG_SIZE = 96\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ------------------------\n",
    "# MODEL CLASS (must match saved model)\n",
    "# ------------------------\n",
    "class SimplerCNN(nn.Module):\n",
    "    def __init__(self, num_classes, img_size=96):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        self.fc1 = nn.Linear(256*2*2, 256)\n",
    "        self.bn_fc = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 26)  # assuming 26 letters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))); x = self.pool(x); x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x))); x = self.pool(x); x = self.dropout(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x))); x = self.pool(x); x = self.dropout(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x))); x = self.pool(x); x = self.dropout(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.bn_fc(self.fc1(x))); x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x)); x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------\n",
    "# AUGMENTATION FUNCTION (light)\n",
    "# ------------------------\n",
    "def apply_augmentation(img, strength='light'):\n",
    "    img_size = img.shape[0]\n",
    "    if np.random.rand() > 0.5:\n",
    "        angle = np.random.uniform(-5, 5)\n",
    "        M = cv2.getRotationMatrix2D((img_size//2, img_size//2), angle, 1.0)\n",
    "        img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "    if np.random.rand() > 0.5:\n",
    "        tx = np.random.randint(-3, 4)\n",
    "        ty = np.random.randint(-3, 4)\n",
    "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        img = cv2.warpAffine(img, M, (img_size, img_size), borderMode=cv2.BORDER_REPLICATE)\n",
    "    return img\n",
    "\n",
    "# ------------------------\n",
    "# LOAD MODEL\n",
    "# ------------------------\n",
    "model = SimplerCNN(num_classes=26, img_size=IMG_SIZE).to(DEVICE)\n",
    "model.load_state_dict(joblib.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# ------------------------\n",
    "# INFERENCE FUNCTION\n",
    "# ------------------------\n",
    "def inference(image_path, tta_rounds=5):\n",
    "    \"\"\"\n",
    "    Predict the letter for a single image using the saved CNN model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path : str\n",
    "        Path to the input image.\n",
    "    tta_rounds : int\n",
    "        Number of augmented versions for test-time augmentation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (predicted_label, confidence)\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot load image: {image_path}\")\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)).astype(np.float32)/255.0\n",
    "    img_tensor = torch.FloatTensor(img).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    # Original prediction\n",
    "    preds = [F.softmax(model(img_tensor), dim=1)]\n",
    "\n",
    "    # TTA predictions\n",
    "    for _ in range(tta_rounds):\n",
    "        aug_img = apply_augmentation(img, strength='light')\n",
    "        aug_tensor = torch.FloatTensor(aug_img).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "        preds.append(F.softmax(model(aug_tensor), dim=1))\n",
    "\n",
    "    # Average predictions\n",
    "    avg_pred = torch.stack(preds).mean(dim=0)\n",
    "    pred_idx = avg_pred.argmax(1).item()\n",
    "    confidence = avg_pred[0, pred_idx].item()\n",
    "\n",
    "    predicted_label = chr(ord('a') + pred_idx)  # assuming labels a-z\n",
    "    return predicted_label, confidence\n",
    "\n",
    "# ------------------------\n",
    "# EXAMPLE USAGE\n",
    "# ------------------------\n",
    "sample_img = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5/Data/Processed/Cursive/S1/f.png\"\n",
    "pred_letter, conf = inference(sample_img)\n",
    "print(f\"Predicted Letter: {pred_letter}, Confidence: {conf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
