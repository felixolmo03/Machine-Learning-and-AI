{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tasked in developing an algorithm in order to detect certain lowercase cursive letters. The program should be able to detect which letter is in an imported image and output the accuracy of that letter being the predicted letter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define base and data paths\n",
    "base_path = \"/home/jupyter-1016468/Git-Repo-Tour/Project_5\"\n",
    "data_dir = os.path.join(base_path, \"Data\")\n",
    "\n",
    "# Define ZIP file paths\n",
    "cursive_zip = os.path.join(data_dir, \"Cursive.zip\")\n",
    "kaggle_zip = os.path.join(data_dir, \"archive.zip\")\n",
    "\n",
    "# Define extraction directories\n",
    "cursive_extract_path = os.path.join(data_dir, \"Cursive\")\n",
    "kaggle_extract_path = os.path.join(data_dir, \"Signatures\")\n",
    "\n",
    "# Make sure folders exist\n",
    "os.makedirs(cursive_extract_path, exist_ok=True)\n",
    "os.makedirs(kaggle_extract_path, exist_ok=True)\n",
    "\n",
    "# --- Unzip the Cursive dataset ---\n",
    "try:\n",
    "    with zipfile.ZipFile(cursive_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(cursive_extract_path)\n",
    "    print(f\"Successfully extracted Cursive.zip to: {cursive_extract_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find Cursive.zip in the Data folder.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: Cursive.zip appears to be corrupted or invalid.\")\n",
    "\n",
    "# --- Unzip the Kaggle signature dataset ---\n",
    "try:\n",
    "    with zipfile.ZipFile(kaggle_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(kaggle_extract_path)\n",
    "    print(f\"Successfully extracted archive.zip to: {kaggle_extract_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find archive.zip in the Data folder.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: archive.zip appears to be corrupted or invalid.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jpg_files = glob.glob(f\"{extract_path}/**/*.jpg\", recursive=True)\n",
    "heic_files = glob.glob(f\"{extract_path}/**/*.heic\", recursive=True)\n",
    "\n",
    "print(\"JPG count:\", len(jpg_files))\n",
    "print(\"HEIC count:\", len(heic_files))\n",
    "\n",
    "\n",
    "sample = random.choice(jpg_files)\n",
    "img = cv2.imread(sample)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(f\"Sample image: {sample.split('/')[-1]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "base_path = \"Data/Cursive\"  # relative to Project_5 notebook\n",
    "subject_folders = [f\"S{i}\" for i in range(1, 36)]\n",
    "\n",
    "# Storage\n",
    "viable_images = []\n",
    "corrupted_images = []\n",
    "\n",
    "# Image size\n",
    "IMG_SIZE = (64, 64)\n",
    "\n",
    "# Loop through all subject folders\n",
    "for folder in subject_folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        continue\n",
    "    for img_file in glob.glob(f\"{folder_path}/*.*\"):\n",
    "        try:\n",
    "            # Convert HEIC to JPG if needed\n",
    "            if img_file.lower().endswith(\".HEIC\"):\n",
    "                img_jpg = img_file.replace(\".HEIC\", \".jpg\")\n",
    "                with Image.open(img_file) as im:\n",
    "                    im.convert(\"RGB\").save(img_jpg, \"JPEG\")\n",
    "                img_file = img_jpg\n",
    "            \n",
    "            # Try reading with OpenCV\n",
    "            img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                corrupted_images.append(img_file)\n",
    "                continue\n",
    "            \n",
    "            # Resize and normalize\n",
    "            img = cv2.resize(img, IMG_SIZE)\n",
    "            img = img / 255.0\n",
    "            \n",
    "            # Store image + label (subject folder)\n",
    "            viable_images.append((img, folder))\n",
    "        except Exception as e:\n",
    "            corrupted_images.append(img_file)\n",
    "\n",
    "print(f\"Total images found: {len(viable_images) + len(corrupted_images)}\")\n",
    "print(f\"Viable images: {len(viable_images)}\")\n",
    "print(f\"Corrupted/unreadable images: {len(corrupted_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "base_path = \"Data/Cursive\"\n",
    "subject_folders = [f\"S{i}\" for i in range(1, 36)]\n",
    "\n",
    "viable_images = []\n",
    "corrupted_images = []\n",
    "converted_count = 0\n",
    "\n",
    "for folder in subject_folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        continue\n",
    "    \n",
    "    for img_file in glob.glob(f\"{folder_path}/*.*\"):\n",
    "        # Convert to JPG if not already\n",
    "        if not img_file.lower().endswith(\".jpg\"):\n",
    "            try:\n",
    "                with Image.open(img_file) as im:\n",
    "                    im = im.convert(\"RGB\")  # ensure it's RGB\n",
    "                    new_path = os.path.splitext(img_file)[0] + \".jpg\"\n",
    "                    im.save(new_path, \"JPEG\")\n",
    "                    converted_count += 1\n",
    "                    os.remove(img_file)  # remove original\n",
    "                    img_file = new_path  # update path to new jpg\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {img_file}: {e}\")\n",
    "                corrupted_images.append(img_file)\n",
    "                continue\n",
    "        \n",
    "        # Check if OpenCV can read it\n",
    "        try:\n",
    "            img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                corrupted_images.append(img_file)\n",
    "            else:\n",
    "                viable_images.append(img_file)\n",
    "        except Exception as e:\n",
    "            corrupted_images.append(img_file)\n",
    "\n",
    "print(f\"Conversion complete! Total files converted to JPG: {converted_count}\")\n",
    "print(f\"Total viable images: {len(viable_images)}\")\n",
    "print(f\"Total corrupted/unreadable images: {len(corrupted_images)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
