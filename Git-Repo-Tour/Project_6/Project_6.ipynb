{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tasked with creating an automated tetris player that can successfully play for an extended period of time. By using a Reinforcement Learning model we will achieve this goal with the several characteristics we can define and configure within the model to make it properly play the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is collected by real-time training through trial and error, the model observes the current state takes and action, then recieves either positive or negative feedback. Data is collected by completing several games overtime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The board consists of a 2D grid that is 10 x 20 that can take in binary values (0 = empty, 1 = filled). There are 7 types of blocks that will be taken into account along with the current roation state of those shapes. Some of the features that will be derived is the board height before each piece is placed, number of holes, bumpiness, number of complete lines, and the individual column heights. The model will be able to rotate the piece 0, 80, 180, or 270 degrees and move its horizontal position as long as it's within the confinments of the board. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly prepare the data we will need to flatten the 10x20 board to a 200-dimensional vector and keep the normslization of 0 for empty 1 for filled. Then feature engineering will include the hand-extracted features. We then need to scale the rewards to a resonable range where positive awards outweigh the negative awards to fuel efficiency in a Reinforcement Learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first attempted creating a DQN model however it came to my attention that not only was each generation very slow but it kept overfitting and learning mostly from failures and little to no successes so the results were very sparse and it never properly learned. I ended up using a genetic algorithm with heuristic weights which worked much better due to the immediate feedback and the heuristic weights were much more comparable to the factors that play into Tetris those being height, holes, bumpiness, etc... after each generation the model improves even slightly and trains much faster and efficiently.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clean Evolutionary Tetris AI - Starting Fresh\n",
    "Simple, working evolutionary algorithm\n",
    "\"\"\"\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "TRAINING_MODE = True\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Evolution settings\n",
    "POPULATION_SIZE = 20\n",
    "ELITE_SIZE = 4\n",
    "MUTATION_RATE = 0.3\n",
    "MUTATION_STRENGTH = 0.2\n",
    "GAMES_PER_INDIVIDUAL = 3\n",
    "\n",
    "# ============================================================================\n",
    "# BOARD EVALUATION\n",
    "# ============================================================================\n",
    "def evaluate_board(board_array):\n",
    "    \"\"\"Calculate board features\"\"\"\n",
    "    height = len(board_array)\n",
    "    width = len(board_array[0])\n",
    "    \n",
    "    # Column heights\n",
    "    heights = []\n",
    "    for col in range(width):\n",
    "        col_height = 0\n",
    "        for row in range(height):\n",
    "            if board_array[row][col]:\n",
    "                col_height = row + 1\n",
    "        heights.append(col_height)\n",
    "    \n",
    "    # Features\n",
    "    aggregate_height = sum(heights)\n",
    "    max_height = max(heights) if heights else 0\n",
    "    \n",
    "    # Holes\n",
    "    holes = 0\n",
    "    for col in range(width):\n",
    "        found_block = False\n",
    "        for row in range(height - 1, -1, -1):\n",
    "            if board_array[row][col]:\n",
    "                found_block = True\n",
    "            elif found_block:\n",
    "                holes += 1\n",
    "    \n",
    "    # Bumpiness\n",
    "    bumpiness = sum(abs(heights[i] - heights[i + 1]) for i in range(len(heights) - 1))\n",
    "    \n",
    "    # Complete lines\n",
    "    complete_lines = sum(1 for row in board_array if all(row))\n",
    "    \n",
    "    # Wells\n",
    "    wells = 0\n",
    "    for i in range(width):\n",
    "        if i == 0:\n",
    "            if heights[i] < heights[i + 1]:\n",
    "                wells += heights[i + 1] - heights[i]\n",
    "        elif i == width - 1:\n",
    "            if heights[i] < heights[i - 1]:\n",
    "                wells += heights[i - 1] - heights[i]\n",
    "        else:\n",
    "            if heights[i] < heights[i - 1] and heights[i] < heights[i + 1]:\n",
    "                wells += min(heights[i - 1], heights[i + 1]) - heights[i]\n",
    "    \n",
    "    return {\n",
    "        'aggregate_height': aggregate_height,\n",
    "        'max_height': max_height,\n",
    "        'holes': holes,\n",
    "        'bumpiness': bumpiness,\n",
    "        'complete_lines': complete_lines,\n",
    "        'wells': wells\n",
    "    }\n",
    "\n",
    "def simulate_placement(board, piece, x):\n",
    "    \"\"\"Simulate placing a piece\"\"\"\n",
    "    board_copy = [row[:] for row in board.board[:board.height]]\n",
    "    \n",
    "    try:\n",
    "        y = board.drop_height(piece, x)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    for pos in piece.body:\n",
    "        row_idx = y + pos[1]\n",
    "        col_idx = x + pos[0]\n",
    "        if 0 <= row_idx < board.height and 0 <= col_idx < board.width:\n",
    "            board_copy[row_idx][col_idx] = True\n",
    "    \n",
    "    return board_copy\n",
    "\n",
    "# ============================================================================\n",
    "# EVOLUTIONARY AGENT\n",
    "# ============================================================================\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        # Start with reasonable initial weights\n",
    "        self.best_weights = {\n",
    "            'aggregate_height': -0.5,\n",
    "            'max_height': -0.5,\n",
    "            'holes': -1.0,\n",
    "            'bumpiness': -0.3,\n",
    "            'complete_lines': 0.8,\n",
    "            'wells': -0.5\n",
    "        }\n",
    "        \n",
    "        self.generation = 0\n",
    "        self.best_score = 0\n",
    "        self.population = []\n",
    "        \n",
    "        # Try to load checkpoint\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, \"evolution.pkl\")\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            try:\n",
    "                with open(checkpoint_path, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                self.best_weights = data['best_weights']\n",
    "                self.generation = data['generation']\n",
    "                self.best_score = data['best_score']\n",
    "                print(f\"Loaded checkpoint: Gen {self.generation}, Score {self.best_score}\")\n",
    "            except:\n",
    "                print(\"Checkpoint corrupted, starting fresh\")\n",
    "        \n",
    "        # Create population\n",
    "        self.create_population()\n",
    "    \n",
    "    def create_population(self):\n",
    "        \"\"\"Create population of weight variations\"\"\"\n",
    "        self.population = []\n",
    "        \n",
    "        # First individual: best weights\n",
    "        self.population.append({\n",
    "            'weights': self.best_weights.copy(),\n",
    "            'scores': []\n",
    "        })\n",
    "        \n",
    "        # Rest: variations\n",
    "        for _ in range(POPULATION_SIZE - 1):\n",
    "            weights = {}\n",
    "            for key, value in self.best_weights.items():\n",
    "                weights[key] = value + random.gauss(0, 0.5)\n",
    "            self.population.append({\n",
    "                'weights': weights,\n",
    "                'scores': []\n",
    "            })\n",
    "    \n",
    "    def evaluate_move(self, board, piece, x, weights):\n",
    "        \"\"\"Evaluate a move\"\"\"\n",
    "        simulated_board = simulate_placement(board, piece, x)\n",
    "        if simulated_board is None:\n",
    "            return -999999\n",
    "        \n",
    "        features = evaluate_board(simulated_board)\n",
    "        score = sum(weights[k] * features[k] for k in weights)\n",
    "        return score\n",
    "    \n",
    "    def get_best_move(self, board, piece, weights):\n",
    "        \"\"\"Find best move for given weights\"\"\"\n",
    "        best_x = 0\n",
    "        best_piece = piece\n",
    "        best_score = -999999\n",
    "        \n",
    "        current_piece = piece\n",
    "        for _ in range(4):\n",
    "            for x in range(board.width):\n",
    "                if x + len(current_piece.skirt) > board.width:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    score = self.evaluate_move(board, current_piece, x, weights)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_x = x\n",
    "                        best_piece = current_piece\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            current_piece = current_piece.get_next_rotation()\n",
    "        \n",
    "        return best_x, best_piece\n",
    "    \n",
    "    def evolve(self):\n",
    "        \"\"\"Evolve to next generation\"\"\"\n",
    "        # Calculate average score for each individual\n",
    "        for ind in self.population:\n",
    "            if ind['scores']:\n",
    "                ind['avg_score'] = sum(ind['scores']) / len(ind['scores'])\n",
    "            else:\n",
    "                ind['avg_score'] = 0\n",
    "        \n",
    "        # Sort by score\n",
    "        self.population.sort(key=lambda x: x['avg_score'], reverse=True)\n",
    "        \n",
    "        # Update best\n",
    "        if self.population[0]['avg_score'] > self.best_score:\n",
    "            self.best_score = self.population[0]['avg_score']\n",
    "            self.best_weights = self.population[0]['weights'].copy()\n",
    "        \n",
    "        # Keep elite\n",
    "        new_population = []\n",
    "        for i in range(ELITE_SIZE):\n",
    "            new_population.append({\n",
    "                'weights': self.population[i]['weights'].copy(),\n",
    "                'scores': []\n",
    "            })\n",
    "        \n",
    "        # Create offspring\n",
    "        while len(new_population) < POPULATION_SIZE:\n",
    "            # Select parents from elite\n",
    "            p1 = random.choice(self.population[:ELITE_SIZE])\n",
    "            p2 = random.choice(self.population[:ELITE_SIZE])\n",
    "            \n",
    "            # Crossover\n",
    "            child_weights = {}\n",
    "            for key in self.best_weights.keys():\n",
    "                child_weights[key] = p1['weights'][key] if random.random() < 0.5 else p2['weights'][key]\n",
    "                \n",
    "                # Mutation\n",
    "                if random.random() < MUTATION_RATE:\n",
    "                    child_weights[key] += random.gauss(0, MUTATION_STRENGTH)\n",
    "            \n",
    "            new_population.append({\n",
    "                'weights': child_weights,\n",
    "                'scores': []\n",
    "            })\n",
    "        \n",
    "        self.population = new_population\n",
    "        self.generation += 1\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, \"evolution.pkl\")\n",
    "        with open(checkpoint_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'best_weights': self.best_weights,\n",
    "                'generation': self.generation,\n",
    "                'best_score': self.best_score\n",
    "            }, f)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN CLASS\n",
    "# ============================================================================\n",
    "_agent = None\n",
    "_current_ind = 0\n",
    "_games_played = 0\n",
    "\n",
    "class CUSTOM_AI_MODEL:\n",
    "    def __init__(self):\n",
    "        global _agent, _current_ind\n",
    "        \n",
    "        if _agent is None:\n",
    "            _agent = Agent()\n",
    "            print(f\"\\nEvolutionary Tetris AI\")\n",
    "            print(f\"Generation: {_agent.generation}\")\n",
    "            print(f\"Population: {POPULATION_SIZE}\")\n",
    "            print(f\"Best score: {_agent.best_score}\\n\")\n",
    "        \n",
    "        self.agent = _agent\n",
    "        \n",
    "        # Get weights for current individual\n",
    "        if _current_ind < len(self.agent.population):\n",
    "            self.weights = self.agent.population[_current_ind]['weights']\n",
    "        else:\n",
    "            self.weights = self.agent.best_weights\n",
    "    \n",
    "    def get_best_move(self, board, piece, depth=1):\n",
    "        \"\"\"Called by game.py\"\"\"\n",
    "        x, selected_piece = self.agent.get_best_move(board, piece, self.weights)\n",
    "        return x, selected_piece\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Called when game ends\"\"\"\n",
    "        global _current_ind, _games_played\n",
    "        \n",
    "        if not TRAINING_MODE:\n",
    "            return\n",
    "        \n",
    "        # Continue training\n",
    "        from game import Game\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # Run game\n",
    "                game = Game(\"student\")\n",
    "                pieces, rows = game.run_no_visual()\n",
    "                \n",
    "                # Calculate score\n",
    "                score = pieces + rows * 100\n",
    "                \n",
    "                # Record score\n",
    "                if _current_ind < len(self.agent.population):\n",
    "                    self.agent.population[_current_ind]['scores'].append(score)\n",
    "                \n",
    "                _games_played += 1\n",
    "                \n",
    "                # Print simple output\n",
    "                print(f\"{pieces} {rows}\")\n",
    "                \n",
    "                # Check if individual is done\n",
    "                if _current_ind < len(self.agent.population):\n",
    "                    if len(self.agent.population[_current_ind]['scores']) >= GAMES_PER_INDIVIDUAL:\n",
    "                        _current_ind += 1\n",
    "                \n",
    "                # Check if generation is done\n",
    "                if _current_ind >= POPULATION_SIZE:\n",
    "                    # Evolve\n",
    "                    self.agent.evolve()\n",
    "                    _current_ind = 0\n",
    "                    \n",
    "                    # Print generation summary\n",
    "                    print(f\"\\n=== Generation {self.agent.generation} ===\")\n",
    "                    print(f\"Best score: {self.agent.best_score:.0f}\")\n",
    "                    print(f\"Best weights: {self.agent.best_weights}\")\n",
    "                    print()\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\nStopped at generation {self.agent.generation}\")\n",
    "            import sys\n",
    "            sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model employs a genetic algorithm to evolve certain heuristic weights for a board evaluation function. For each piece placement decision, the algorithm simulates all possible positions and rotations in a game of Tetris, it then evaluates each resulting board state using six weighted features (aggregate height, maximum height, holes, bumpiness, complete lines, and wells), and selects the placement with the highest weighted score. The weights are evolved over generations using a population of 20 individuals, where each individual represents a unique weight tested across 5 games to compute average fitness. After evaluation, the top 4 generations are preserved, while the remaining population is generated through crossover and mutation of the elite parents. This process iterates across generations, with the target network updating after each generation to incorporate the best-performing weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from game import Game\n",
    "\n",
    "try:\n",
    "    g = Game(\"student\")\n",
    "    g.run_no_visual()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining stopped\")\n",
    "    print(\"Checkpoint saved to: checkpoints/evolution.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
